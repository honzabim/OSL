{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: import of Adapt.adapt into FluxExtensions conflicts with an existing identifier; ignored.\n"
     ]
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST\n",
    "using Flux: onehotbatch, argmax, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "using FluxExtensions\n",
    "\n",
    "push!(LOAD_PATH, \"../\")\n",
    "using KNNmem\n",
    "\n",
    "include(\"../train_and_track.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " false  false  false   true  false  …  false  false  false  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       " false   true  false  false  false      true  false  false  false  false\n",
       " false  false  false  false  false     false   true  false  false  false\n",
       " false  false  false  false   true     false  false   true  false  false\n",
       " false  false  false  false  false  …  false  false  false   true  false\n",
       " false  false  false  false  false     false  false  false  false   true\n",
       "  true  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "imgs = MNIST.images()\n",
    "X = hcat(float.(reshape.(imgs, :))...)\n",
    "\n",
    "labels = MNIST.labels()\n",
    "Y = labels\n",
    "oneHotY = Flux.onehotbatch(Y, 0:9) # for softmax\n",
    "\n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...)\n",
    "tY = MNIST.labels(:test)\n",
    "oneHotTY = Flux.onehotbatch(tY, 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(ResDense(Dense(32, 32, NNlib.relu)), ResDense(Dense(10, 10, NNlib.relu)), NNlib.softmax)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with memory\n",
    "\n",
    "memoryModel = Chain(\n",
    "  FluxExtensions.ResDense(28^2, 32, relu),\n",
    "  FluxExtensions.ResDense(32, 10, relu))\n",
    "\n",
    "memory = KNNmemory(1000, 10, 128, 10)\n",
    "\n",
    "# Model without memory\n",
    "\n",
    "classicModel = Chain(\n",
    "  FluxExtensions.ResDense(28^2, 32, relu),\n",
    "  FluxExtensions.ResDense(32, 10, relu),\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training setup\n",
    "\n",
    "memLoss(x, y) = trainQuery!(memory, memoryModel(x), y)\n",
    "memAccuracy(x, y) = mean(query(memory, memoryModel(x)) .== y)\n",
    "memOpt = ADAM(params(memoryModel))\n",
    "\n",
    "classicLoss(x, y) = crossentropy(classicModel(x), y)\n",
    "classicAccuracy(x, y) = mean(argmax(classicModel(x)) .== argmax(y))\n",
    "classicOpt = ADAM(params(classicModel))\n",
    "\n",
    "iterations = 1000\n",
    "batchSize = 1000\n",
    "printInterationCount = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "memHistory = trainAndTrack!(memLoss, memOpt, iterations, batchSize, X, Y, tX, tY, printInterationCount)\n",
    "classicHistory = trainAndTrack!(classicLoss, classicOpt, iterations, batchSize, X, oneHotY, tX, oneHotTY, printInterationCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy comparison\n",
    "\n",
    "memAccuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classicAccuracy(tX, oneHotTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training\n",
    "\n",
    "using Plots\n",
    "pyplot()\n",
    "\n",
    "plot(memHistory)\n",
    "plot!(title = \"Training with memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(classicHistory)\n",
    "plot!(title = \"Training without memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
